{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d867484",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18cf8dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "23/11/09 19:13:32 WARN Utils: Your hostname, LorenzoMorabito resolves to a loopback address: 127.0.1.1; using 172.24.67.165 instead (on interface eth0)\n",
      "23/11/09 19:13:32 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/11/09 19:13:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"Datamanipulation\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e64796c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.24.67.165:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Datamanipulation</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fd68c553a50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cb29770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read our data - lives in a csv file\n",
    "path = '/home/unix/git_repo/PySparkExercise/'\n",
    "file = 'Sample - EU Superstore.csv'\n",
    "df = spark.read.csv(path + file, header= True, inferSchema= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------+----------+----------+--------------+-----------+--------------+---------+-------------+-------+--------------+------+---------------+---------------+------------+--------------------+-------+--------+--------+-------+\n",
      "|Row ID|       Order ID|Order Date| Ship Date|     Ship Mode|Customer ID| Customer Name|  Segment|         City|  State|       Country|Region|     Product ID|       Category|Sub-Category|        Product Name|  Sales|Quantity|Discount| Profit|\n",
      "+------+---------------+----------+----------+--------------+-----------+--------------+---------+-------------+-------+--------------+------+---------------+---------------+------------+--------------------+-------+--------+--------+-------+\n",
      "|     1|ES-2017-1311038|07/02/2017|11/02/2017|Standard Class|   AS-10045|Aaron Smayling|Corporate|        Leeds|England|United Kingdom| North|OFF-ST-10000988|Office Supplies|     Storage|Fellowes Folders,...|   79.2|       3|     0.0|   39.6|\n",
      "|     2|ES-2017-1311038|07/02/2017|11/02/2017|Standard Class|   AS-10045|Aaron Smayling|Corporate|        Leeds|England|United Kingdom| North|TEC-AC-10004144|     Technology| Accessories|SanDisk Numeric K...| 388.92|       7|     0.0|    0.0|\n",
      "|     3|ES-2017-1311038|07/02/2017|11/02/2017|Standard Class|   AS-10045|Aaron Smayling|Corporate|        Leeds|England|United Kingdom| North|OFF-LA-10001915|Office Supplies|      Labels|Avery Legal Exhib...|  35.19|       3|     0.0|  16.11|\n",
      "|     4|ES-2017-1311038|07/02/2017|11/02/2017|Standard Class|   AS-10045|Aaron Smayling|Corporate|        Leeds|England|United Kingdom| North|OFF-ST-10004550|Office Supplies|     Storage|Fellowes Folders,...|  50.94|       2|     0.0|   13.2|\n",
      "|     5|ES-2017-1311038|07/02/2017|11/02/2017|Standard Class|   AS-10045|Aaron Smayling|Corporate|        Leeds|England|United Kingdom| North|TEC-AC-10004068|     Technology| Accessories|Memorex Memory Ca...| 307.44|       3|     0.0|  73.71|\n",
      "|     6|ES-2017-1311038|07/02/2017|11/02/2017|Standard Class|   AS-10045|Aaron Smayling|Corporate|        Leeds|England|United Kingdom| North|OFF-ST-10002271|Office Supplies|     Storage|Rogers Shelving, ...|  122.4|       2|     0.0|  37.92|\n",
      "|     7|ES-2017-1311038|07/02/2017|11/02/2017|Standard Class|   AS-10045|Aaron Smayling|Corporate|        Leeds|England|United Kingdom| North|TEC-PH-10003963|     Technology|      Phones|Apple Signal Boos...| 413.82|       3|     0.0|  20.61|\n",
      "|     8|ES-2015-5113958|02/08/2015|07/08/2015|  Second Class|   EB-13840| Ellis Ballard|Corporate|West Bromwich|England|United Kingdom| North|TEC-CO-10004325|     Technology|     Copiers|Canon Personal Co...| 428.22|       3|     0.0| 192.69|\n",
      "|     9|ES-2015-5113958|02/08/2015|07/08/2015|  Second Class|   EB-13840| Ellis Ballard|Corporate|West Bromwich|England|United Kingdom| North|OFF-AP-10004512|Office Supplies|  Appliances|   Hoover Stove, Red|3979.29|       7|     0.0|1989.54|\n",
      "|    10|ES-2015-5113958|02/08/2015|07/08/2015|  Second Class|   EB-13840| Ellis Ballard|Corporate|West Bromwich|England|United Kingdom| North|OFF-FA-10002393|Office Supplies|   Fasteners|Accos Push Pins, ...|  43.56|       3|     0.0|   12.6|\n",
      "+------+---------------+----------+----------+--------------+-----------+--------------+---------+-------------+-------+--------------+------+---------------+---------------+------------+--------------------+-------+--------+--------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c800030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2827"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many rows of the EU Superstore dataset have the country being France\n",
    "df.filter(df['Country'] == 'France').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "648e5f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2329"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# of those, how many are profitable?\n",
    "df.filter((df['Country'] == 'France') & (df['Profit'] > 0)).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca611b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how any different discount brackets exist? what are they?\n",
    "df.select('Discount').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|Discount|\n",
      "+--------+\n",
      "|     0.0|\n",
      "|     0.2|\n",
      "|     0.7|\n",
      "|     0.1|\n",
      "|    0.45|\n",
      "|     0.6|\n",
      "|    0.35|\n",
      "|     0.5|\n",
      "|    0.85|\n",
      "|    0.65|\n",
      "|     0.8|\n",
      "|     0.4|\n",
      "|    0.15|\n",
      "|     0.3|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('Discount').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2e1f9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+\n",
      "|Discount|Rounded_Profit|\n",
      "+--------+--------------+\n",
      "|     0.0|     383806.53|\n",
      "|     0.1|     126884.03|\n",
      "|    0.15|      24677.56|\n",
      "|     0.2|       2189.55|\n",
      "|     0.3|       -758.42|\n",
      "|    0.35|      -9122.65|\n",
      "|     0.4|     -21346.43|\n",
      "|    0.45|      -1103.19|\n",
      "|     0.5|     -96632.12|\n",
      "|     0.6|     -20517.46|\n",
      "|    0.65|      -6221.97|\n",
      "|     0.7|      -5496.77|\n",
      "|     0.8|       -460.28|\n",
      "|    0.85|      -3068.66|\n",
      "+--------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let's see the totl profit by discount bracket, make sure they are ordered by \n",
    "from pyspark.sql.functions import sum, round\n",
    "df_discount = df.groupBy('Discount').agg(round(sum('Profit'), 2).alias('Rounded_Profit')).orderBy('Discount')\n",
    "df_discount.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1d76050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+\n",
      "|Discount|Rounded_Profit|\n",
      "+--------+--------------+\n",
      "|     0.2|       2189.55|\n",
      "+--------+--------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# what is the value after which we should stop offering discount?\n",
    "df_discount.orderBy(df_discount['Discount'].desc()).filter(df_discount['Rounded_Profit'] >= 0).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aae94ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------+\n",
      "|    Customer Name|Total Profit|\n",
      "+-----------------+------------+\n",
      "|     Susan Pistek|     4974.51|\n",
      "|    Patrick Jones|      3986.0|\n",
      "|Patrick O'Donnell|      3778.2|\n",
      "|    Ellis Ballard|     3459.66|\n",
      "|  Mike Gockenbach|     3144.44|\n",
      "+-----------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# who are the top 5 most profitable customers\n",
    "df_customers = df.groupBy('Customer Name').agg(round(sum('Profit'), 2).alias('Total Profit')) \\\n",
    "    .orderBy('Total Profit', ascending= False).limit(5)\n",
    "    \n",
    "df_customers.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "277c465a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all the rows belonging to those 5 customer names: \n",
    "# hint, you may need the collect method - \n",
    "# how many rows are they?\n",
    "l = []\n",
    "for item in df_customers.collect():\n",
    "    l.append(item[0])\n",
    "    \n",
    "df.filter(df['Customer Name'].isin(l)).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d0fc034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------+----------+----------+--------------+-----------+--------------+---------+-----+-------+--------------+------+---------------+---------------+------------+--------------------+------+--------+--------+------+-------------+\n",
      "|Row ID|       Order ID|Order Date| Ship Date|     Ship Mode|Customer ID| Customer Name|  Segment| City|  State|       Country|Region|     Product ID|       Category|Sub-Category|        Product Name| Sales|Quantity|Discount|Profit|Original_sale|\n",
      "+------+---------------+----------+----------+--------------+-----------+--------------+---------+-----+-------+--------------+------+---------------+---------------+------------+--------------------+------+--------+--------+------+-------------+\n",
      "|     1|ES-2017-1311038|07/02/2017|11/02/2017|Standard Class|   AS-10045|Aaron Smayling|Corporate|Leeds|England|United Kingdom| North|OFF-ST-10000988|Office Supplies|     Storage|Fellowes Folders,...|  79.2|       3|     0.0|  39.6|         79.2|\n",
      "|     2|ES-2017-1311038|07/02/2017|11/02/2017|Standard Class|   AS-10045|Aaron Smayling|Corporate|Leeds|England|United Kingdom| North|TEC-AC-10004144|     Technology| Accessories|SanDisk Numeric K...|388.92|       7|     0.0|   0.0|       388.92|\n",
      "|     3|ES-2017-1311038|07/02/2017|11/02/2017|Standard Class|   AS-10045|Aaron Smayling|Corporate|Leeds|England|United Kingdom| North|OFF-LA-10001915|Office Supplies|      Labels|Avery Legal Exhib...| 35.19|       3|     0.0| 16.11|        35.19|\n",
      "|     4|ES-2017-1311038|07/02/2017|11/02/2017|Standard Class|   AS-10045|Aaron Smayling|Corporate|Leeds|England|United Kingdom| North|OFF-ST-10004550|Office Supplies|     Storage|Fellowes Folders,...| 50.94|       2|     0.0|  13.2|        50.94|\n",
      "|     5|ES-2017-1311038|07/02/2017|11/02/2017|Standard Class|   AS-10045|Aaron Smayling|Corporate|Leeds|England|United Kingdom| North|TEC-AC-10004068|     Technology| Accessories|Memorex Memory Ca...|307.44|       3|     0.0| 73.71|       307.44|\n",
      "+------+---------------+----------+----------+--------------+-----------+--------------+---------+-----+-------+--------------+------+---------------+---------------+------------+--------------------+------+--------+--------+------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a new column which is the value of the sale \n",
    "# were there not discount applied. Hint: orginal = sales/(1-d)\n",
    "\n",
    "df = df.withColumn('Original_sale', round(df['Sales']/ (1 - df['Discount']), 2))\n",
    "df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba0f9aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------+----------+----------+--------------+-----------+--------------+---------+-----+-------+--------------+------+---------------+---------------+------------+--------------------+------+--------+--------+------+-------------+----------+\n",
      "|Row ID|       Order ID|Order Date| Ship Date|     Ship Mode|Customer ID| Customer Name|  Segment| City|  State|       Country|Region|     Product ID|       Category|Sub-Category|        Product Name| Sales|Quantity|Discount|Profit|Original_sale|Diff_sales|\n",
      "+------+---------------+----------+----------+--------------+-----------+--------------+---------+-----+-------+--------------+------+---------------+---------------+------------+--------------------+------+--------+--------+------+-------------+----------+\n",
      "|     1|ES-2017-1311038|07/02/2017|11/02/2017|Standard Class|   AS-10045|Aaron Smayling|Corporate|Leeds|England|United Kingdom| North|OFF-ST-10000988|Office Supplies|     Storage|Fellowes Folders,...|  79.2|       3|     0.0|  39.6|         79.2|       0.0|\n",
      "|     2|ES-2017-1311038|07/02/2017|11/02/2017|Standard Class|   AS-10045|Aaron Smayling|Corporate|Leeds|England|United Kingdom| North|TEC-AC-10004144|     Technology| Accessories|SanDisk Numeric K...|388.92|       7|     0.0|   0.0|       388.92|       0.0|\n",
      "|     3|ES-2017-1311038|07/02/2017|11/02/2017|Standard Class|   AS-10045|Aaron Smayling|Corporate|Leeds|England|United Kingdom| North|OFF-LA-10001915|Office Supplies|      Labels|Avery Legal Exhib...| 35.19|       3|     0.0| 16.11|        35.19|       0.0|\n",
      "|     4|ES-2017-1311038|07/02/2017|11/02/2017|Standard Class|   AS-10045|Aaron Smayling|Corporate|Leeds|England|United Kingdom| North|OFF-ST-10004550|Office Supplies|     Storage|Fellowes Folders,...| 50.94|       2|     0.0|  13.2|        50.94|       0.0|\n",
      "|     5|ES-2017-1311038|07/02/2017|11/02/2017|Standard Class|   AS-10045|Aaron Smayling|Corporate|Leeds|England|United Kingdom| North|TEC-AC-10004068|     Technology| Accessories|Memorex Memory Ca...|307.44|       3|     0.0| 73.71|       307.44|       0.0|\n",
      "+------+---------------+----------+----------+--------------+-----------+--------------+---------+-----+-------+--------------+------+---------------+---------------+------------+--------------------+------+--------+--------+------+-------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate the difference between sales and discount value\n",
    "df = df.withColumn('Diff_sales', df['Sales'] - df['Original_sale'])\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e810f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+\n",
      "|Discount|      Loss|\n",
      "+--------+----------+\n",
      "|     0.0|       0.0|\n",
      "|     0.1| -84712.45|\n",
      "|    0.15| -45233.18|\n",
      "|     0.2| -10653.12|\n",
      "|     0.3|  -2630.24|\n",
      "|    0.35|  -29163.1|\n",
      "|     0.4| -46724.69|\n",
      "|    0.45|  -2083.44|\n",
      "|     0.5|-183734.27|\n",
      "|     0.6| -39644.05|\n",
      "|    0.65| -12219.66|\n",
      "|     0.7|  -8534.09|\n",
      "|     0.8|   -635.66|\n",
      "|    0.85|  -4515.44|\n",
      "+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# how much money did we not gain due to the discounts - per discount bracket?\n",
    "df_loss = df.groupBy('Discount').agg(round(sum('Diff_sales'), 2).alias('Loss')).orderBy('Discount')\n",
    "df_loss.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76aca9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|  Max_loss|\n",
      "+----------+\n",
      "|-183734.27|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# find the discount bracket which made us not gain the most (dynamically)\n",
    "from pyspark.sql.functions import min\n",
    "df_loss.agg(min(df_loss['Loss']).alias('Max_loss')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0aa9b685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "469461.86"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what would have been the total profit if we removed all orders from that discount group? \n",
    "max_profit = df.filter(df['Discount'] != 0.5).agg(round(sum(df['Profit']), 2).alias('Max_profit')).collect()[0]['Max_profit']\n",
    "max_profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fca95e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "372829.74"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how much more (or less) profit is that?\n",
    "total_profit = df.agg(round(sum(df['Profit']), 2).alias('Total_profit')).collect()[0]['Total_profit']\n",
    "total_profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96632.12"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference_profit = max_profit - total_profit\n",
    "difference_profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0fb49200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a temporary table for our superstore table in sql\n",
    "df.createOrReplaceTempView('superstore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------+----------+----------+--------------+-----------+--------------+---------+-----+-------+--------------+------+---------------+---------------+------------+--------------------+------+--------+--------+------+-------------+----------+\n",
      "|Row ID|       Order ID|Order Date| Ship Date|     Ship Mode|Customer ID| Customer Name|  Segment| City|  State|       Country|Region|     Product ID|       Category|Sub-Category|        Product Name| Sales|Quantity|Discount|Profit|Original_sale|Diff_sales|\n",
      "+------+---------------+----------+----------+--------------+-----------+--------------+---------+-----+-------+--------------+------+---------------+---------------+------------+--------------------+------+--------+--------+------+-------------+----------+\n",
      "|     1|ES-2017-1311038|07/02/2017|11/02/2017|Standard Class|   AS-10045|Aaron Smayling|Corporate|Leeds|England|United Kingdom| North|OFF-ST-10000988|Office Supplies|     Storage|Fellowes Folders,...|  79.2|       3|     0.0|  39.6|         79.2|       0.0|\n",
      "|     2|ES-2017-1311038|07/02/2017|11/02/2017|Standard Class|   AS-10045|Aaron Smayling|Corporate|Leeds|England|United Kingdom| North|TEC-AC-10004144|     Technology| Accessories|SanDisk Numeric K...|388.92|       7|     0.0|   0.0|       388.92|       0.0|\n",
      "|     3|ES-2017-1311038|07/02/2017|11/02/2017|Standard Class|   AS-10045|Aaron Smayling|Corporate|Leeds|England|United Kingdom| North|OFF-LA-10001915|Office Supplies|      Labels|Avery Legal Exhib...| 35.19|       3|     0.0| 16.11|        35.19|       0.0|\n",
      "|     4|ES-2017-1311038|07/02/2017|11/02/2017|Standard Class|   AS-10045|Aaron Smayling|Corporate|Leeds|England|United Kingdom| North|OFF-ST-10004550|Office Supplies|     Storage|Fellowes Folders,...| 50.94|       2|     0.0|  13.2|        50.94|       0.0|\n",
      "|     5|ES-2017-1311038|07/02/2017|11/02/2017|Standard Class|   AS-10045|Aaron Smayling|Corporate|Leeds|England|United Kingdom| North|TEC-AC-10004068|     Technology| Accessories|Memorex Memory Ca...|307.44|       3|     0.0| 73.71|       307.44|       0.0|\n",
      "+------+---------------+----------+----------+--------------+-----------+--------------+---------+-----+-------+--------------+------+---------------+---------------+------------+--------------------+------+--------+--------+------+-------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM superstore LIMIT 5\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a23e0bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|N_rows|\n",
      "+------+\n",
      "| 10000|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use an SQL query to count the number of rows\n",
    "spark.sql(\"SELECT COUNT(*) as N_rows FROM superstore\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8e2cf9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+\n",
      "|       Country|Profit_ratio|\n",
      "+--------------+------------+\n",
      "|   Switzerland|        0.29|\n",
      "|       Austria|        0.26|\n",
      "|        Norway|        0.25|\n",
      "|       Belgium|        0.24|\n",
      "|United Kingdom|        0.21|\n",
      "|       Finland|        0.19|\n",
      "|         Spain|        0.19|\n",
      "|       Germany|        0.17|\n",
      "|        France|        0.13|\n",
      "|         Italy|        0.07|\n",
      "|       Ireland|       -0.44|\n",
      "|       Denmark|        -0.5|\n",
      "|   Netherlands|       -0.53|\n",
      "|        Sweden|       -0.57|\n",
      "|      Portugal|       -0.58|\n",
      "+--------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use an SQL query to calculate the profit ratio for each country: hint, ratio is sum(profit)/sum(sales)\n",
    "spark.sql(\"SELECT Country, ROUND(sum(profit)/ sum(sales), 2) as Profit_ratio FROM superstore GROUP BY Country ORDER BY Profit_ratio DESC\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f8cdd772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+\n",
      "|       Country|Tot_profit|\n",
      "+--------------+----------+\n",
      "|United Kingdom| 111900.15|\n",
      "+--------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# is the country with the largest profit ratio, the country with the largest profit?\n",
    "spark.sql(\"SELECT Country,  ROUND(SUM(Profit), 2) as Tot_profit FROM superstore GROUP BY Country ORDER BY Tot_profit DESC LIMIT 1\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_profit_country = spark.sql(\"SELECT Country, \\\n",
    "                                ROUND(SUM(Profit), 2) as Tot_profit \\\n",
    "                                FROM superstore \\\n",
    "                                GROUP BY Country \\\n",
    "                                ORDER BY Tot_profit \\\n",
    "                                DESC LIMIT 1\").first()[0]\n",
    "\n",
    "best_ratio_counrty = spark.sql('''SELECT Country, \n",
    "          ROUND(sum(profit)/ sum(sales), 2) as Profit_ratio \n",
    "          FROM superstore \n",
    "          GROUP BY Country \n",
    "          ORDER BY Profit_ratio DESC''').first()[0]\n",
    "\n",
    "best_profit_country == best_ratio_counrty"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
